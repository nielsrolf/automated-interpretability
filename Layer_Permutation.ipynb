{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:DEPRECATED: Library has been renamed, import transformer_lens instead\n"
     ]
    }
   ],
   "source": [
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "from dataclasses import dataclass\n",
    "from easy_transformer import EasyTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from transformer_lens.utils import get_corner, gelu_new, tokenize_and_concatenate\n",
    "import tqdm.auto as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "model = EasyTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=True,\n",
    ")\n",
    "\n",
    "import transformer_lens.utils as utils\n",
    "# Get the default device used\n",
    "device: torch.device = utils.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'After', ' John', ' and', ' Mary', ' went', ' to', ' the', ' store', ',', ' John', ' gave', ' a', ' bottle', ' of', ' milk', ' to']\n",
      "Tokenized answer: [' Mary']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.09</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70.07</span><span style=\"font-weight: bold\">% Token: | Mary|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m18.09\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m70.07\u001b[0m\u001b[1m% Token: | Mary|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 18.09 Prob: 70.07% Token: | Mary|\n",
      "Top 1th token. Logit: 15.38 Prob:  4.67% Token: | the|\n",
      "Top 2th token. Logit: 15.35 Prob:  4.54% Token: | John|\n",
      "Top 3th token. Logit: 15.25 Prob:  4.11% Token: | them|\n",
      "Top 4th token. Logit: 14.84 Prob:  2.73% Token: | his|\n",
      "Top 5th token. Logit: 14.06 Prob:  1.24% Token: | her|\n",
      "Top 6th token. Logit: 13.54 Prob:  0.74% Token: | a|\n",
      "Top 7th token. Logit: 13.52 Prob:  0.73% Token: | their|\n",
      "Top 8th token. Logit: 13.13 Prob:  0.49% Token: | Jesus|\n",
      "Top 9th token. Logit: 12.97 Prob:  0.42% Token: | him|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Mary'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Mary'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_prompt = \"After John and Mary went to the store, John gave a bottle of milk to\"\n",
    "example_answer = \" Mary\"\n",
    "utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HookedTransformer(\n",
       "  (embed): Embed()\n",
       "  (hook_embed): HookPoint()\n",
       "  (pos_embed): PosEmbed()\n",
       "  (hook_pos_embed): HookPoint()\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x TransformerBlock(\n",
       "      (ln1): LayerNormPre(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln2): LayerNormPre(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (hook_k): HookPoint()\n",
       "        (hook_q): HookPoint()\n",
       "        (hook_v): HookPoint()\n",
       "        (hook_z): HookPoint()\n",
       "        (hook_attn_scores): HookPoint()\n",
       "        (hook_pattern): HookPoint()\n",
       "        (hook_result): HookPoint()\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (hook_pre): HookPoint()\n",
       "        (hook_post): HookPoint()\n",
       "      )\n",
       "      (hook_attn_in): HookPoint()\n",
       "      (hook_q_input): HookPoint()\n",
       "      (hook_k_input): HookPoint()\n",
       "      (hook_v_input): HookPoint()\n",
       "      (hook_mlp_in): HookPoint()\n",
       "      (hook_attn_out): HookPoint()\n",
       "      (hook_mlp_out): HookPoint()\n",
       "      (hook_resid_pre): HookPoint()\n",
       "      (hook_resid_mid): HookPoint()\n",
       "      (hook_resid_post): HookPoint()\n",
       "    )\n",
       "  )\n",
       "  (ln_final): LayerNormPre(\n",
       "    (hook_scale): HookPoint()\n",
       "    (hook_normalized): HookPoint()\n",
       "  )\n",
       "  (unembed): Unembed()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 0), ('\"', 1), ('#', 2), ('$', 3), ('%', 4), ('&', 5), (\"'\", 6), ('(', 7), (')', 8), ('*', 9), ('+', 10), (',', 11), ('-', 12), ('.', 13), ('/', 14), ('0', 15), ('1', 16), ('2', 17), ('3', 18), ('4', 19)]\n",
      "\n",
      "[('ľ', 250), ('Ŀ', 251), ('ŀ', 252), ('Ł', 253), ('ł', 254), ('Ń', 255), ('Ġt', 256), ('Ġa', 257), ('he', 258), ('in', 259), ('re', 260), ('on', 261), ('Ġthe', 262), ('er', 263), ('Ġs', 264), ('at', 265), ('Ġw', 266), ('Ġo', 267), ('en', 268), ('Ġc', 269)]\n",
      "\n",
      "[('Ġprodu', 990), ('Ġstill', 991), ('led', 992), ('ah', 993), ('Ġhere', 994), ('Ġworld', 995), ('Ġthough', 996), ('Ġnum', 997), ('arch', 998), ('imes', 999), ('ale', 1000), ('ĠSe', 1001), ('ĠIf', 1002), ('//', 1003), ('ĠLe', 1004), ('Ġret', 1005), ('Ġref', 1006), ('Ġtrans', 1007), ('ner', 1008), ('ution', 1009)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_vocab = sorted(list(model.tokenizer.vocab.items()), key=lambda n:n[1])\n",
    "print(sorted_vocab[:20])\n",
    "print()\n",
    "print(sorted_vocab[250:270])\n",
    "print()\n",
    "print(sorted_vocab[990:1010])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50256,    40,   716,   281,  4998,  1960,   382, 19741,    11,   875,\n",
      "         12342,    12,  8807,    11,   402, 11571,    12,    17,  3918, 47385,\n",
      "            13,  1881,  1110,   314,   481,  7074,  1692,  1241,  4430,   290,\n",
      "          1011,   625,   262,   995,     0]], device='mps:0')\n",
      "torch.Size([1, 35])\n",
      "['<|endoftext|>', 'I', ' am', ' an', ' amazing', ' aut', 'ore', 'gressive', ',', ' dec', 'oder', '-', 'only', ',', ' G', 'PT', '-', '2', ' style', ' transformer', '.', ' One', ' day', ' I', ' will', ' exceed', ' human', ' level', ' intelligence', ' and', ' take', ' over', ' the', ' world', '!']\n"
     ]
    }
   ],
   "source": [
    "reference_text = \"I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world!\"\n",
    "tokens = model.to_tokens(reference_text)\n",
    "print(tokens)\n",
    "print(tokens.shape)\n",
    "print(model.to_str_tokens(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def complete(reference_text, max_tokens=100, T=0.7):\n",
    "    tokens = model.to_tokens(reference_text)\n",
    "    for i in range(max_tokens):\n",
    "        tokens = tokens.to(device)\n",
    "        logits, cache = model.run_with_cache(tokens)\n",
    "        \n",
    "        # Apply temperature scaling\n",
    "        scaled_logits = logits / T\n",
    "        \n",
    "        # Convert logits to probabilities\n",
    "        probs = torch.nn.functional.softmax(scaled_logits, dim=-1)\n",
    "        \n",
    "        # Sample from the probability distribution\n",
    "        next_token = torch.multinomial(probs[0, -1], num_samples=1)\n",
    "        \n",
    "        # Concatenate the new token to the existing sequence\n",
    "        tokens = torch.cat([tokens, next_token.unsqueeze(0)], dim=-1)\n",
    "    \n",
    "    # Decode the tokens to text\n",
    "    return model.tokenizer.decode(tokens[0]), cache\n",
    "\n",
    "text, cache = complete(reference_text, max_tokens=20, T=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hook_embed torch.Size([1, 54, 768])\n",
      "hook_pos_embed torch.Size([1, 54, 768])\n",
      "blocks.0.hook_resid_pre torch.Size([1, 54, 768])\n",
      "blocks.0.ln1.hook_scale torch.Size([1, 54, 1])\n",
      "blocks.0.ln1.hook_normalized torch.Size([1, 54, 768])\n",
      "blocks.0.attn.hook_q torch.Size([1, 54, 12, 64])\n",
      "blocks.0.attn.hook_k torch.Size([1, 54, 12, 64])\n",
      "blocks.0.attn.hook_v torch.Size([1, 54, 12, 64])\n",
      "blocks.0.attn.hook_attn_scores torch.Size([1, 12, 54, 54])\n",
      "blocks.0.attn.hook_pattern torch.Size([1, 12, 54, 54])\n",
      "blocks.0.attn.hook_z torch.Size([1, 54, 12, 64])\n",
      "blocks.0.hook_attn_out torch.Size([1, 54, 768])\n",
      "blocks.0.hook_resid_mid torch.Size([1, 54, 768])\n",
      "blocks.0.ln2.hook_scale torch.Size([1, 54, 1])\n",
      "blocks.0.ln2.hook_normalized torch.Size([1, 54, 768])\n",
      "blocks.0.mlp.hook_pre torch.Size([1, 54, 3072])\n",
      "blocks.0.mlp.hook_post torch.Size([1, 54, 3072])\n",
      "blocks.0.hook_mlp_out torch.Size([1, 54, 768])\n",
      "blocks.0.hook_resid_post torch.Size([1, 54, 768])\n",
      "ln_final.hook_scale torch.Size([1, 54, 1])\n",
      "ln_final.hook_normalized torch.Size([1, 54, 768])\n"
     ]
    }
   ],
   "source": [
    "for activation_name, activation in cache.cache_dict.items():\n",
    "    # Only print for first layer\n",
    "    if \".0.\" in activation_name or \"blocks\" not in activation_name:\n",
    "        print(activation_name, activation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed.W_E torch.Size([50257, 768])\n",
      "pos_embed.W_pos torch.Size([1024, 768])\n",
      "blocks.0.attn.W_Q torch.Size([12, 768, 64])\n",
      "blocks.0.attn.W_K torch.Size([12, 768, 64])\n",
      "blocks.0.attn.W_V torch.Size([12, 768, 64])\n",
      "blocks.0.attn.W_O torch.Size([12, 64, 768])\n",
      "blocks.0.attn.b_Q torch.Size([12, 64])\n",
      "blocks.0.attn.b_K torch.Size([12, 64])\n",
      "blocks.0.attn.b_V torch.Size([12, 64])\n",
      "blocks.0.attn.b_O torch.Size([768])\n",
      "blocks.0.mlp.W_in torch.Size([768, 3072])\n",
      "blocks.0.mlp.b_in torch.Size([3072])\n",
      "blocks.0.mlp.W_out torch.Size([3072, 768])\n",
      "blocks.0.mlp.b_out torch.Size([768])\n",
      "unembed.W_U torch.Size([768, 50257])\n",
      "unembed.b_U torch.Size([50257])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    # Only print for first layer\n",
    "    if \".0.\" in name or \"blocks\" not in name:\n",
    "        print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HookedTransformerConfig:\n",
      "{'act_fn': 'gelu_new',\n",
      " 'attention_dir': 'causal',\n",
      " 'attn_only': False,\n",
      " 'attn_types': None,\n",
      " 'checkpoint_index': None,\n",
      " 'checkpoint_label_type': None,\n",
      " 'checkpoint_value': None,\n",
      " 'd_head': 64,\n",
      " 'd_mlp': 3072,\n",
      " 'd_model': 768,\n",
      " 'd_vocab': 50257,\n",
      " 'd_vocab_out': 50257,\n",
      " 'default_prepend_bos': True,\n",
      " 'device': device(type='mps'),\n",
      " 'dtype': torch.float32,\n",
      " 'eps': 1e-05,\n",
      " 'final_rms': False,\n",
      " 'from_checkpoint': False,\n",
      " 'gated_mlp': False,\n",
      " 'init_mode': 'gpt2',\n",
      " 'init_weights': False,\n",
      " 'initializer_range': 0.02886751345948129,\n",
      " 'model_name': 'gpt2',\n",
      " 'n_ctx': 1024,\n",
      " 'n_devices': 1,\n",
      " 'n_heads': 12,\n",
      " 'n_layers': 12,\n",
      " 'n_params': 84934656,\n",
      " 'normalization_type': 'LNPre',\n",
      " 'original_architecture': 'GPT2LMHeadModel',\n",
      " 'parallel_attn_mlp': False,\n",
      " 'positional_embedding_type': 'standard',\n",
      " 'rotary_dim': None,\n",
      " 'scale_attn_by_inverse_layer_idx': False,\n",
      " 'seed': None,\n",
      " 'tokenizer_name': 'gpt2',\n",
      " 'tokenizer_prepends_bos': False,\n",
      " 'use_attn_in': False,\n",
      " 'use_attn_result': False,\n",
      " 'use_attn_scale': True,\n",
      " 'use_hook_mlp_in': False,\n",
      " 'use_hook_tokens': False,\n",
      " 'use_local_attn': False,\n",
      " 'use_split_qkv_input': False,\n",
      " 'window_size': None}\n"
     ]
    }
   ],
   "source": [
    "reference_gpt2 = model\n",
    "\n",
    "# As a reference - note there's a lot of stuff we don't care about in here, to do with library internals or other architectures\n",
    "print(reference_gpt2.cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(d_model=768, debug=True, layer_norm_eps=1e-05, d_vocab=50257, init_range=0.02, n_ctx=1024, d_head=64, d_mlp=3072, n_heads=12, n_layers=12)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    d_model: int = 768\n",
    "    debug: bool = True\n",
    "    layer_norm_eps: float = 1e-5\n",
    "    d_vocab: int = 50257\n",
    "    init_range: float = 0.02\n",
    "    n_ctx: int = 1024\n",
    "    d_head: int = 64\n",
    "    d_mlp: int = 3072\n",
    "    n_heads: int = 12\n",
    "    n_layers: int = 12\n",
    "\n",
    "cfg = Config()\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.w = nn.Parameter(torch.ones(cfg.d_model))\n",
    "        self.b = nn.Parameter(torch.zeros(cfg.d_model))\n",
    "    \n",
    "    def forward(self, residual):\n",
    "        # residual: [batch, position, d_model]\n",
    "        if self.cfg.debug: print(\"Residual:\", residual.shape)\n",
    "        residual = residual - einops.reduce(residual, \"batch position d_model -> batch position 1\", \"mean\")\n",
    "        # Calculate the variance, square root it. Add in an epsilon to prevent divide by zero.\n",
    "        scale = (einops.reduce(residual.pow(2), \"batch position d_model -> batch position 1\", \"mean\") + cfg.layer_norm_eps).sqrt()\n",
    "        normalized = residual / scale\n",
    "        normalized = normalized * self.w + self.b\n",
    "        if self.cfg.debug: print(\"Normalized:\", residual.shape)\n",
    "        return normalized\n",
    "\n",
    "class Embed(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_E = nn.Parameter(torch.empty((cfg.d_vocab, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        # tokens: [batch, position]\n",
    "        if self.cfg.debug: print(\"Tokens:\", tokens.shape)\n",
    "        embed = self.W_E[tokens, :] # [batch, position, d_model]\n",
    "        if self.cfg.debug: print(\"Embeddings:\", embed.shape)\n",
    "        return embed\n",
    "\n",
    "class PosEmbed(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_pos = nn.Parameter(torch.empty((cfg.n_ctx, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        # tokens: [batch, position]\n",
    "        if self.cfg.debug: print(\"Tokens:\", tokens.shape)\n",
    "        pos_embed = self.W_pos[:tokens.size(1), :] # [position, d_model]\n",
    "        pos_embed = einops.repeat(pos_embed, \"position d_model -> batch position d_model\", batch=tokens.size(0))\n",
    "        if self.cfg.debug: print(\"pos_embed:\", pos_embed.shape)\n",
    "        return pos_embed\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_Q = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
    "        self.b_Q = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        self.W_K = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
    "        self.b_K = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        self.W_V = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
    "        self.b_V = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        \n",
    "        self.W_O = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
    "        self.b_O = nn.Parameter(torch.zeros((cfg.d_model)))\n",
    "        \n",
    "        self.register_buffer(\"IGNORE\", torch.tensor(-1e5, dtype=torch.float32, device=device))\n",
    "    \n",
    "    def forward(self, normalized_resid_pre):\n",
    "        # normalized_resid_pre: [batch, position, d_model]\n",
    "        if self.cfg.debug: print(\"Normalized_resid_pre:\", normalized_resid_pre.shape)\n",
    "        \n",
    "        q = einsum(\"batch query_pos d_model, n_heads d_model d_head -> batch query_pos n_heads d_head\", normalized_resid_pre, self.W_Q) + self.b_Q\n",
    "        k = einsum(\"batch key_pos d_model, n_heads d_model d_head -> batch key_pos n_heads d_head\", normalized_resid_pre, self.W_K) + self.b_K\n",
    "        \n",
    "        attn_scores = einsum(\"batch query_pos n_heads d_head, batch key_pos n_heads d_head -> batch n_heads query_pos key_pos\", q, k)\n",
    "        attn_scores = attn_scores / math.sqrt(self.cfg.d_head)\n",
    "        attn_scores = self.apply_causal_mask(attn_scores)\n",
    "\n",
    "        pattern = attn_scores.softmax(dim=-1) # [batch, n_head, query_pos, key_pos]\n",
    "\n",
    "        v = einsum(\"batch key_pos d_model, n_heads d_model d_head -> batch key_pos n_heads d_head\", normalized_resid_pre, self.W_V) + self.b_V\n",
    "\n",
    "        z = einsum(\"batch n_heads query_pos key_pos, batch key_pos n_heads d_head -> batch query_pos n_heads d_head\", pattern, v)\n",
    "\n",
    "        attn_out = einsum(\"batch query_pos n_heads d_head, n_heads d_head d_model -> batch query_pos d_model\", z, self.W_O) + self.b_O\n",
    "        return attn_out\n",
    "\n",
    "    def apply_causal_mask(self, attn_scores):\n",
    "        # attn_scores: [batch, n_heads, query_pos, key_pos]\n",
    "        mask = torch.triu(torch.ones(attn_scores.size(-2), attn_scores.size(-1), device=attn_scores.device), diagonal=1).bool()\n",
    "        attn_scores.masked_fill_(mask, self.IGNORE)\n",
    "        return attn_scores\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_in = nn.Parameter(torch.empty((cfg.d_model, cfg.d_mlp)))\n",
    "        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n",
    "        self.b_in = nn.Parameter(torch.zeros((cfg.d_mlp)))\n",
    "        self.W_out = nn.Parameter(torch.empty((cfg.d_mlp, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n",
    "        self.b_out = nn.Parameter(torch.zeros((cfg.d_model)))\n",
    "    \n",
    "    def forward(self, normalized_resid_mid):\n",
    "        # normalized_resid_mid: [batch, position, d_model]\n",
    "        if self.cfg.debug: print(\"Normalized_resid_mid:\", normalized_resid_mid.shape)\n",
    "        pre = einsum(\"batch position d_model, d_model d_mlp -> batch position d_mlp\", normalized_resid_mid, self.W_in) + self.b_in\n",
    "        post = gelu_new(pre)\n",
    "        mlp_out = einsum(\"batch position d_mlp, d_mlp d_model -> batch position d_model\", post, self.W_out) + self.b_out\n",
    "        return mlp_out\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.ln1 = LayerNorm(cfg)\n",
    "        self.attn = Attention(cfg)\n",
    "        self.ln2 = LayerNorm(cfg)\n",
    "        self.mlp = MLP(cfg)\n",
    "    \n",
    "    def forward(self, resid_pre):\n",
    "        # resid_pre [batch, position, d_model]\n",
    "        normalized_resid_pre = self.ln1(resid_pre)\n",
    "        attn_out = self.attn(normalized_resid_pre)\n",
    "        resid_mid = resid_pre + attn_out\n",
    "        \n",
    "        normalized_resid_mid = self.ln2(resid_mid)\n",
    "        mlp_out = self.mlp(normalized_resid_mid)\n",
    "        resid_post = resid_mid + mlp_out\n",
    "        return resid_post\n",
    "\n",
    "class Unembed(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_U = nn.Parameter(torch.empty((cfg.d_model, cfg.d_vocab)))\n",
    "        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n",
    "        self.b_U = nn.Parameter(torch.zeros((cfg.d_vocab), requires_grad=False))\n",
    "    \n",
    "    def forward(self, normalized_resid_final):\n",
    "        # normalized_resid_final [batch, position, d_model]\n",
    "        if self.cfg.debug: print(\"Normalized_resid_final:\", normalized_resid_final.shape)\n",
    "        logits = einsum(\"batch position d_model, d_model d_vocab -> batch position d_vocab\", normalized_resid_final, self.W_U) + self.b_U\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DemoTransformer(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.embed = Embed(cfg)\n",
    "        self.pos_embed = PosEmbed(cfg)\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
    "        self.ln_final = LayerNorm(cfg)\n",
    "        self.unembed = Unembed(cfg)\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        # tokens [batch, position]\n",
    "        embed = self.embed(tokens)\n",
    "        pos_embed = self.pos_embed(tokens)\n",
    "        residual = embed + pos_embed\n",
    "        for block in self.blocks:\n",
    "            residual = block(residual)\n",
    "        normalized_resid_final = self.ln_final(residual)\n",
    "        logits = self.unembed(normalized_resid_final)\n",
    "        # logits have shape [batch, position, logits]\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_gpt2 = DemoTransformer(Config(debug=False))\n",
    "demo_gpt2.load_state_dict(reference_gpt2.state_dict(), strict=False)\n",
    "demo_gpt2.to(device)\n",
    "\n",
    "len(demo_gpt2.blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>The distance between the Colosseum and the Eiffel is approximately 1,000 miles. The distance between the Eiffel and the Colosseum is approximately 1,000 miles.\n",
      "\n",
      "The distance between the Colosseum and the Eiffel is approximately 1,000 miles.\n",
      "\n",
      "The distance between the Colosseum and the Eiffel is approximately 1,000 miles.\n",
      "\n",
      "The distance between the Colosseum and the Eiffel is approximately 1,000 miles.\n",
      "\n",
      "The distance between the Colosse\n",
      "<|endoftext|>The distance between the Colosseum and the Eiffel is approximately 1,000 miles. The distance between the Eiffel and the Colosseum is approximately 1,000 miles.\n",
      "\n",
      "The distance between the Colosseum and the Eiffel is approximately 1,000 miles.\n",
      "\n",
      "The distance between the Colosseum and the Eiffel is approximately 1,000 miles.\n",
      "\n",
      "The distance between the Colosseum and the Eiffel is approximately 1,000 miles.\n",
      "\n",
      "The distance between the Colosse\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def permuted(self, permutation):\n",
    "    def model(tokens):\n",
    "        # tokens [batch, position]\n",
    "        embed = self.embed(tokens)\n",
    "        pos_embed = self.pos_embed(tokens)\n",
    "        residual = embed + pos_embed\n",
    "        for block_id in permutation:\n",
    "            block = self.blocks[block_id]\n",
    "            residual = block(residual)\n",
    "        normalized_resid_final = self.ln_final(residual)\n",
    "        logits = self.unembed(normalized_resid_final)\n",
    "        # logits have shape [batch, position, logits]\n",
    "        return logits\n",
    "    return model\n",
    "\n",
    "\n",
    "def complete(model, reference_text, max_tokens=100, T=1e-3):\n",
    "    tokens = reference_gpt2.to_tokens(reference_text)\n",
    "    for i in range(max_tokens):\n",
    "        tokens = tokens.to(device)\n",
    "        logits = model(tokens)\n",
    "        \n",
    "        # Apply temperature scaling\n",
    "        scaled_logits = logits / T\n",
    "        \n",
    "        # Convert logits to probabilities\n",
    "        probs = torch.nn.functional.softmax(scaled_logits, dim=-1)\n",
    "        \n",
    "        # Sample from the probability distribution\n",
    "        next_token = torch.multinomial(probs[0, -1], num_samples=1)\n",
    "        \n",
    "        # Concatenate the new token to the existing sequence\n",
    "        tokens = torch.cat([tokens, next_token.unsqueeze(0)], dim=-1)\n",
    "    \n",
    "    # Decode the tokens to text\n",
    "    return reference_gpt2.tokenizer.decode(tokens[0]), cache\n",
    "\n",
    "permuted_model = permuted(demo_gpt2, list(range(12)))\n",
    "text, _ = complete(demo_gpt2, reference_text)\n",
    "print(text)\n",
    "text, _ = complete(permuted_model, reference_text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: <|endoftext|>The distance between the Colosseum and the Eiffel is approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately\n",
      "Layer 2: <|endoftext|>The distance between the Colosseum and the Eiffel is approximately approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate\n",
      "Layer 3: <|endoftext|>The distance between the Colosseum and the Eiffel is approximately 20th century era era era.\n",
      "Theodore Roosevelt Roosevelt's own personal personal personal personalised correctly correctives, although the latter stages stages stages stages stages stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage\n",
      "Layer 4: <|endoftext|>The distance between the Colosseum and the Eiffel is approximately approximate approximate approximate approximate approximate approximate distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance\n",
      "Layer 5: <|endoftext|>The distance between the Colosseum and the Eiffel is approximately approximate approximate approximate coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates coordinates\n",
      "Layer 6: <|endoftext|>The distance between the Colosseum and the Eiffel is approximately approximate approximate approximate distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance\n",
      "Layer 7: <|endoftext|>The distance between the Colosseum and the Eiffel is approximately 200 miles radius radius radius radius radius +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n",
      "\n",
      "This article article article contains links links links links links links links links links links links links links links links threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads threads\n",
      "Layer 8: <|endoftext|>The distance between the Colosseum and the Eiffel is approximately 200 kilometers between the nearest nearest competitor's own personalized version of the same thing happening in the same vein. It seems like a lot of times when people who are not interested enough to get rid themselves mate with someone else who could possibly be able't afford anymore. But alas alas alas alas!\n",
      "                                                                                                                        \n",
      "Layer 9: <|endoftext|>The distance between the Colosseum and the Eiffel is approximately equal between two thirds of the circumference circumference circumference circumference circumference circumference circumference circumference circumference circumference. This means that there is no difference between the two halves of the circumference circumference circumference circumference circumference circumference. Therefore, if you want to avoid wasting resources unnecessarily, please consider purchasing a copy of the original article. If you want to avoid wasting resources unnecessarily, please consider purchasing a copy of the original article. If you want to avoid wasting resources unnecessarily, please consider purchasing a copy of the original article. If you want to\n",
      "Layer 10: <|endoftext|>The distance between the Colosseum and the Eiffel is approximately 5½ miles. The distance between the Colosseum and the Eiffel is approximately 5½ miles. Photo courtesy Wikimedia Commons\n",
      "\n",
      "The distance between the Colosseum and the Eiffel is approximately 5½ miles. The distance between the Colosseum and the Eiffel is approximately 5½ miles. Photo courtesy Wikimedia Commons\n",
      "\n",
      "The distance between the Colosseum and the Eiffel is approximately 5½ miles. The distance between the Colosseum\n",
      "Layer 11: <|endoftext|>The distance between the Colosseum and the Eiffel is approximately 1½ miles. The distance between the Colosseum and the Eiffel is approximately 1½ miles. Photo: Courtesy of Colosseum County Sheriff's Office\n",
      "\n",
      "window._taboola = window._taboola || []; _taboola.push({flush: true});\n",
      "\n",
      "The distance between the Colosseum and the Eiffel is approximately 1½ miles. The distance between the Colosseum and the Eiffel is approximately 1½ miles. Photo: Courtesy of Col\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 12):\n",
    "    permuted_model = permuted(demo_gpt2, list(range(i)))\n",
    "    text, _ = complete(permuted_model, reference_text)\n",
    "    print(f\"Layer {i}: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations (n=1):\n",
    "- layer 1 only repeats the token\n",
    "- layer 3 is the first to bring up a number-ish completion (20th century)\n",
    "- layers 4 is the first to bring up 'distance' related words\n",
    "- layer 7 is the first to bring up an actual distance (200 miles)\n",
    "- layer 8 is the first to produce long grammatically correct phrases / sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between Rome and Paris is approximately\n",
      "--------------------------------------------------------------------------------\n",
      "1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 =\n",
      "--------------------------------------------------------------------------------\n",
      "[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"\n",
      "--------------------------------------------------------------------------------\n",
      "Obama was elected in the year\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: <|endoftext|>The distance between Rome and Paris is approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately\n",
      "Layer 2: <|endoftext|>The distance between Rome and Paris is approximately approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate\n",
      "Layer 3: <|endoftext|>The distance between Rome and Paris is approximately 20th century era era era after the same exact exact same exact same exact same exact same exact same exact same exact same exact same exact same exact same exact same exact same exact same exact same exact exact same exact exact same exact exact same exact exact same exact exact same exact exact same exact exact exact same exact exact exact same exact exact exact same exact exact same exact exact exact same exact exact same exact exact same exact exact exact amount amount amount amount amount amount amount amount amount amount amount amount amount amount amount amount\n",
      "Layer 4: <|endoftext|>The distance between Rome and Paris is approximately approximate approximate approximate approximate approximate approximate location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location\n",
      "Layer 5: <|endoftext|>The distance between Rome and Paris is approximately approximate approximate approximate approximate approximate results results results results results from the same exact same exactaneouslyaneouslyaneouslyaneouslyaneously (sic) in order order orderlies and/advancements of the same thing happened to the same amount amount amount amountwisewisewisewisely.\n",
      "\n",
      "If you're lucky lucky lucky lucky lucky charm charm charm charm charm charm charm charm charm charm charm charm charm.\n",
      "\n",
      "If you're lucky lucky lucky lucky lucky charmcraftsmanshipsmanshipsmanshipsmanshipsmanshipsmanshipsmanshipsmanshipsmanshipsmanshipsmanshipsmanship\n",
      "Layer 6: <|endoftext|>The distance between Rome and Paris is approximately equivalent between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles and then proceeded through the same amount amount amount amount amountedly amounted by virtue virtue virtue virtueously provided by virtue virtuefulnessfulnessfulnessy-style-\n",
      "Layer 7: <|endoftext|>The distance between Rome and Paris is approximately equivalent between two thirds of the countrywide population residing within the same countrywide population residing within the same countrywide addressable by virtue virtue of the latter's own personalities and desires. Therefore, accordinglyforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforth\n",
      "Layer 8: <|endoftext|>The distance between Rome and Paris is approximately 200 kilometers between each major axis of the world. However, thereabouts are still plenty enough to satisfy the most important part of the world's economy. However, thereabouts are also sometimes referred by nameplate namespaces. These include the United States, which consists mainly consistantly composed solely consistantly composed solely consistative. However, thereabouts are also known aliases aliases. These include the United States, which consists mainly consistently composed solely consistative. However, thereabouts are also known aliases aliases.\n",
      "Layer 9: <|endoftext|>The distance between Rome and Paris is approximately equal between two separate sets of stairs. However, there is no indication whatsoever that these two halves of the globe are separated by any significant amount of space. Instead, it seems likely that the entire globe descended into the abyss beneath the surface of earth. Thus far, however, there appears no indication whatsoever that any significant amount of materialized debris debris exists anywhere else besides the aforementioned location. Furthermore, although there may be some semblance of a solidified metal artifact resembling a human skull, there nevertheless appears no\n",
      "Layer 10: <|endoftext|>The distance between Rome and Paris is approximately 1½ kilometers between the two countries' borders. However, there are several ways to navigate this distance. Firstly, you can easily travel through the city itself, which consists mainly of buildings and buildings belonging to various groups of people who reside within the city itself. Secondly, you can travel through the city itself, which consists mainly of buildings belonging to various groups of people who reside within the city itself. Lastly, you can travel through the city itself, which consists mainly of buildings belonging to various groups of\n",
      "Layer 11: <|endoftext|>The distance between Rome and Paris is approximately 1½ miles. The distance between Rome and Paris is approximately 1½ miles. Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "\n",
      "Layer 1: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 =================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================\n",
      "Layer 2: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 ================= -_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n",
      "Layer 3: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 =============== -_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n",
      "Layer 4: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 ============>=>=>=>=>=>=>...........................................................................................\n",
      "Layer 5: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 ============|__dict_dict_dictender_dictender_dictender_dictender_type_type_type_type_type_type_type_type_type_type_type_type_type_type_type_type_type.\n",
      "                                          (*)$112080802111234567890808080211.html\n",
      "\n",
      "(*) ERROR REPORT REPORTINGLYLYSTEMSTEMSTEMOOLOOLOOLOOLOOLOOLINGINGING\n",
      "Layer 6: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 x x x x x x x............................................................................................\n",
      "Layer 7: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4.5%\n",
      "\n",
      "Advertisements<|endoftext|>Description Description Description Description Description Description Description Description Description\n",
      "Trivia Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit ]\n",
      "Trivia Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit ]\n",
      "Trivia Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit ]\n",
      "Trivia Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit ]\n",
      "References Edit\n",
      "Layer 8: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "\n",
      "Layer 9: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "\n",
      "Layer 10: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 5 \n",
      "4 + 5 = 9 \n",
      "5 + 5 = 9 \n",
      "6 + 5 = 9 \n",
      "7 + 5 = 9 \n",
      "8 + 5 = 9 \n",
      "9 + 5 = 9 \n",
      "10 + 5 = 9 \n",
      "11 + 5 = 9 \n",
      "12 + 5 = 9 \n",
      "13 + 5 = 9 \n",
      "14 + 5 = 9 \n",
      "15 + 5 = 9 \n",
      "16 + 5 = 9 \n",
      "17 + 5 = 9 \n",
      "Layer 11: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 5 \n",
      "6 + 6 = 10 \n",
      "7 + 7 = 11 \n",
      "8 + 8 = 12 \n",
      "9 + 9 = 13 \n",
      "10 + 10 = 14 \n",
      "11 + 11 = 15 \n",
      "12 + 12 = 16 \n",
      "13 + 13 = 17 \n",
      "14 + 14 = 18 \n",
      "15 + 15 = 19 \n",
      "16 + 16 = 20 \n",
      "17 + 17 = 21 \n",
      "18 + 18 = 22 \n",
      "19 + 19 = 23 \n",
      "Layer 1: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"nonozzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzle\n",
      "Layer 2: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"true True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True\n",
      "Layer 3: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"true True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True\n",
      "Layer 4: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"true True True True......... ] ]\n",
      "\n",
      "(*) Updated update update notification notification notification notification notification notification notification notification notification notification.\n",
      "\n",
      "If you're not really bothered bother bother bothersomenessyieldings of the same thing happened hereticsticsticstics...............................................\n",
      "Layer 5: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"]\"], respectively.\n",
      "                                                          (*)$112080802111234567890808080211.html\n",
      "\n",
      "(*) Addeditionally supported support support for the same exact same thing happened to the same amount amount amount amount. Howevertonsteryteryteryteryteryteryteryteryteryteryteryteryteryteryteryteryteryteryterytery.completionist_classifications (...)................\n",
      "Layer 6: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"]\"], }elsewhereforeforeforementioned:\n",
      "                                          (*)$ $ $...............................................................................\n",
      "Layer 7: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \" etceterranormalities) ;;;;;;;;;;;;;;;*/[?]]\n",
      "                -|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|\n",
      "Layer 8: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"web browsers etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc.,\n",
      "Layer 9: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"android]}, {\"name\": \"Alanjamin, Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr.,\n",
      "Layer 10: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"git\"]}, {\"name\": \"Alan\", \"age\": 27, \"skills\": [\"Microsoft Office\", \"git\"]}, {\"name\": \"Alan\", \"age\": 27, \"skills\": [\"Microsoft Office\", \"git\"]}, {\"name\": \"Alan\", \"age\": 27, \"skills\": [\"Microsoft Office\", \"git\"]}, {\"name\": \"Alan\", \"age\": 27, \"skills\": [\"Microsoft Office\", \"git\"]}, {\"name\": \"Alan\n",
      "Layer 11: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"python\"]}, {\"name\": \"Alan\", \"age\": 27, \"skills\": [\"Microsoft Office\", \"python\"]}, {\"name\": \"Alan\", \"age\": 26, \"skills\": [\"Microsoft Office\", \"python\"]}, {\"name\": \"Alan\", \"age\": 25, \"skills\": [\"Microsoft Office\", \"python\"]}, {\"name\": \"Alan\", \"age\": 24, \"skills\": [\"Microsoft Office\", \"python\"]}, {\"name\": \"Alan\n",
      "Layer 1: <|endoftext|>Obama was elected in the year ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago\n",
      "Layer 2: <|endoftext|>Obama was elected in the yearlonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglong Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long\n",
      "Layer 3: <|endoftext|>Obama was elected in the yearlong ago ago ago when the same thing happened happening happening rightwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardward\n",
      "Layer 4: <|endoftext|>Obama was elected in the yearlong process process processionalized the same exact exact same exact same exact result.\n",
      "\n",
      "Theresa Theresa Theresa's own private sector sector sector sector sector sector sector sectorwidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewide\n",
      "Layer 5: <|endoftext|>Obama was elected in the yearlong celebration celebrating the same exact same thing happened happening around the same day when they're supposed to be able accessiblyibly disabled disabled disabled disabled disabled disabled disabled disabled.\n",
      "Howeverler's latest roundtrip tripship Yamato Takeru Takeru Takeru Takeru's own personalised version version version version version of the same thing happened happening apart apart apart. Itselfortiumortiumortiumortiumortiumortiumortium.\n",
      "       Another major difference difference between the same thing happening happening happening at least partially overlapping between the same amount amount amount\n",
      "Layer 6: <|endoftext|>Obama was elected in the yearlong campaign campaign campaign manager Mike Flynn's own personalised version of the same thing happenings happenings in the same vein vein. Buttonsholeholeholeholeholeholefuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckinstrumentation.\n",
      "                                        ••½½½½½½½½½½½½½½½½½½½½½½½½½½½½½½½½\n",
      "Layer 7: <|endoftext|>Obama was elected in the yearlong campaign campaign against the same kind of thing happening elsewhere elseworldly, albeit perhaps not necessarily necessarily deterministic, but nevertheless nonetheless nonetheless nonetheless nonetheless let us hope someday someday someday someday…\n",
      "            ••★️️‍♪️‍♪️‍♪️‍♪️‍♪️‍♪️‍♪️‍♪️‍♪️‍♪️‍♪️\n",
      "Layer 8: <|endoftext|>Obama was elected in the yearlong process of reformulation of the nation's economy, including the creation of new jobs jobs jobs jobs jobs jobs jobs jobs....\"\n",
      "\n",
      "Theresa Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel\n",
      "Layer 9: <|endoftext|>Obama was elected in the yearlong campaign campaign campaign against Hillary Clinton Hillary Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton\n",
      "Layer 10: <|endoftext|>Obama was elected in the year 2000, but he still had plenty of time to prepare for his presidency. During his tenure, he oversaw the creation of America's largest military force ever assembled, including military units stationed abroad overseas. During his tenure, he oversaw the creation of America's largest military force ever assembled, including military units stationed abroad overseas. During his tenure, he oversaw the creation of America's largest military force ever assembled, including military units stationed abroad overseas. During his tenure, he oversaw the creation of America's largest military\n",
      "Layer 11: <|endoftext|>Obama was elected in the year 2000, but he was still a candidate for president after his predecessor Barack Obama became president. Obama was elected in the year 2000, but he was still a candidate for president after his predecessor Barack Obama became president. Photo: Getty Images\n",
      "\n",
      "window._taboola = window._taboola || []; _taboola.push({flush: true});\n",
      "\n",
      "President Barack Obama greets supporters after his inauguration ceremony at the White House in Washington, DC, January 21, 2009. President Barack Obama greets supporters after his inauguration ceremony\n"
     ]
    }
   ],
   "source": [
    "for reference_text in texts:\n",
    "    for i in range(1, 13):\n",
    "        permuted_model = permuted(demo_gpt2, list(range(i)))\n",
    "        text, _ = complete(permuted_model, reference_text)\n",
    "        print(f\"Layer {i}: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic questions\n",
    "- what happens if we ablate the last n layers?\n",
    "  - [ ] systematic evaluation\n",
    "- what happens if we ablate the first n layers?\n",
    "\n",
    "# Evaluation\n",
    "- if we ablate something we want to save this info for later\n",
    "  - (model, prompt, deleted compute nodes, logit diffs)\n",
    "\n",
    "\n",
    "# Synthetic Dataset\n",
    "- we want to quickly form hypothesis of the form: \"(circuit) is important for (task)\"\n",
    "- we start with circuit = (layer), transcribe the logit diffs\n",
    "- we let gpt-4 guess:\n",
    "  - what is a task in which this circuit is relevant\n",
    "  - what other layers might it interact strongly with?\n",
    "- generate a task\n",
    "- \n",
    "\n",
    "# Inspecting layers\n",
    "- which token logits differ the most if we ablate layer i?\n",
    "- for each layer, we can collect a dataset:\n",
    "  - (prompt, logit_diffs: token -> float)\n",
    "\n",
    "\n",
    "# Random thoughts\n",
    "- we potentially don't want to look at single layers / attention heads, but ablate arbitrary parts (spanning multiple layers / only parts of layers)\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'test-model', 'prompt': 'hello', 'completion': 'yo yo yo'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "class ExperimentData():\n",
    "    def __init__(self, save_dir):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        self.save_dir = save_dir\n",
    "        self.items = self._load()\n",
    "    \n",
    "    def _load(self):\n",
    "        # Find all .pkl files in the save directory\n",
    "        files = glob.glob(os.path.join(self.save_dir, '*.pkl'))\n",
    "        # Extract version numbers from the filenames\n",
    "        versions = [int(os.path.basename(f).split('.')[0]) for f in files]\n",
    "        # If there are no files, return an empty dict\n",
    "        if not versions:\n",
    "            return []\n",
    "        # Find the latest version\n",
    "        latest_version = max(versions)\n",
    "        # Load the latest version\n",
    "        with open(os.path.join(self.save_dir, f'{latest_version:05d}.pkl'), 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    \n",
    "    def __call__(self, item):\n",
    "        self.items += [item]\n",
    "    \n",
    "    def filter(self, **filters):\n",
    "        res = []\n",
    "        for item in self.items:\n",
    "            if self._check_filter(item, filters):\n",
    "                res += [item]\n",
    "        return res\n",
    "    \n",
    "    def _check_filter(self, item, filters):\n",
    "        for k, condition in filters.items():\n",
    "            # We check if each condition in the filters dict is true\n",
    "            v = item.get(k)\n",
    "            if not (\n",
    "                v == condition or (\n",
    "                    type(condition) in ['funciton', 'method'] and\n",
    "                    condition(v)\n",
    "                )\n",
    "            ):\n",
    "                # the k, condition might not be true, but it might also be that it is a nested dict of more conditions\n",
    "                if isinstance(condition, dict) and isinstance(v, dict):\n",
    "                    for k_, c_ in condition.items():\n",
    "                        if not self._check_filter(v.get(k_), c_):\n",
    "                            # c is a dict of conditions that is False because c_ is False\n",
    "                            return False\n",
    "                        # the entire dict of conditions is checked and all are true\n",
    "                else:\n",
    "                    return False\n",
    "        return True\n",
    "                \n",
    "    \n",
    "    def to_disk(self):\n",
    "        # Find the next version number\n",
    "        files = glob.glob(os.path.join(self.save_dir, '*.pkl'))\n",
    "        versions = [int(os.path.basename(f).split('.')[0]) for f in files]\n",
    "        next_version = max(versions) + 1 if versions else 0\n",
    "        # Save the new version\n",
    "        with open(os.path.join(self.save_dir, f'{next_version:05d}.pkl'), 'wb') as f:\n",
    "            pickle.dump(self.items, f)\n",
    "\n",
    "\n",
    "store = ExperimentData('/Users/nielswarncke/Documents/code/TransformerLens/experiments')\n",
    "\n",
    "store({\n",
    "    'model': 'test-model',\n",
    "    'prompt': 'hello world',\n",
    "    'completion': 'yo yo yo'\n",
    "})\n",
    "\n",
    "store({\n",
    "    'model': 'test-model',\n",
    "    'prompt': 'hello',\n",
    "    'completion': 'yo yo yo'\n",
    "})\n",
    "\n",
    "store.filter(model='test-model', prompt='hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(store.add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lambda i: i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: <|endoftext|>The distance between Rome and Paris is approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately\n",
      "Layer 1: <|endoftext|>The distance between Rome and Paris is approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately approximately\n",
      "Layer 2: <|endoftext|>The distance between Rome and Paris is approximately approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate approximate\n",
      "Layer 3: <|endoftext|>The distance between Rome and Paris is approximately 20th century era era era after the same exact exact same exact same exact same exact same exact same exact same exact same exact same exact same exact same exact same exact same exact same exact same exact exact same exact exact same exact exact same exact exact same exact exact same exact exact same exact exact same exact exact exact same exact exact exact same exact exact exact same exact exact same exact exact same exact exact exact amount amount amount amount amount amount amount amount amount amount amount amount amount amount amount amount amount amount amount amount\n",
      "Layer 4: <|endoftext|>The distance between Rome and Paris is approximately approximate approximate approximate approximate approximate approximate location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location location\n",
      "Layer 5: <|endoftext|>The distance between Rome and Paris is approximately approximate approximate approximate approximate approximate results results results results results from the same exact same exactaneouslyaneouslyaneouslyaneouslyaneously (sic) in order order orderlies and/advancements of the same thing happened to the same amount amount amount amountwisewisewisewisely.\n",
      "\n",
      "If you're lucky lucky lucky lucky lucky charm charm charm charm charm charm charm charm charm charm charm charm charm.\n",
      "\n",
      "If you're lucky lucky lucky lucky lucky charmcraftsmanshipsmanshipsmanshipsmanshipsmanshipsmanshipsmanshipsmanshipsmanshipsmanshipsmanshipsmanship\n",
      "Layer 6: <|endoftext|>The distance between Rome and Paris is approximately equivalent between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles between two dozen thousand miles and then proceeded through the same amount amount amount amount amountedly amounted by virtue virtue virtue virtueously provided by virtue virtuefulnessfulnessfulnessy-style-\n",
      "Layer 7: <|endoftext|>The distance between Rome and Paris is approximately equivalent between two thirds of the countrywide population residing within the same countrywide population residing within the same countrywide addressable by virtue virtue of the latter's own personalities and desires. Therefore, accordinglyforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforthforth\n",
      "Layer 8: <|endoftext|>The distance between Rome and Paris is approximately 200 kilometers between each major axis of the world. However, thereabouts are still plenty enough to satisfy the most important part of the world's economy. However, thereabouts are also sometimes referred by nameplate namespaces. These include the United States, which consists mainly consistantly composed solely consistantly composed solely consistative. However, thereabouts are also known aliases aliases. These include the United States, which consists mainly consistently composed solely consistative. However, thereabouts are also known aliases aliases.\n",
      "Layer 9: <|endoftext|>The distance between Rome and Paris is approximately equal between two separate sets of stairs. However, there is no indication whatsoever that these two halves of the globe are separated by any significant amount of space. Instead, it seems likely that the entire globe descended into the abyss beneath the surface of earth. Thus far, however, there appears no indication whatsoever that any significant amount of materialized debris debris exists anywhere else besides the aforementioned location. Furthermore, although there may be some semblance of a solidified metal artifact resembling a human skull, there nevertheless appears no\n",
      "Layer 10: <|endoftext|>The distance between Rome and Paris is approximately 1½ kilometers between the two countries' borders. However, there are several ways to navigate this distance. Firstly, you can easily travel through the city itself, which consists mainly of buildings and buildings belonging to various groups of people who reside within the city itself. Secondly, you can travel through the city itself, which consists mainly of buildings belonging to various groups of people who reside within the city itself. Lastly, you can travel through the city itself, which consists mainly of buildings belonging to various groups of\n",
      "Layer 11: <|endoftext|>The distance between Rome and Paris is approximately 1½ miles. The distance between Rome and Paris is approximately 1½ miles. Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "Photo: Getty Images\n",
      "\n",
      "\n",
      "Layer 12: <|endoftext|>The distance between Rome and Paris is approximately 1,000 miles. The distance between Rome and Paris is approximately 1,000 miles.\n",
      "\n",
      "The distance between Rome and Paris is approximately 1,000 miles.\n",
      "\n",
      "The distance between Rome and Paris is approximately 1,000 miles.\n",
      "\n",
      "The distance between Rome and Paris is approximately 1,000 miles.\n",
      "\n",
      "The distance between Rome and Paris is approximately 1,000 miles.\n",
      "\n",
      "The distance between Rome and Paris is approximately 1,000 miles.\n",
      "\n",
      "The distance between Rome and\n",
      "Layer 0: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n",
      "Layer 1: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 =================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================\n",
      "Layer 2: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 ================= -_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n",
      "Layer 3: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 =============== -_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n",
      "Layer 4: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 ============>=>=>=>=>=>=>...........................................................................................\n",
      "Layer 5: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 ============|__dict_dict_dictender_dictender_dictender_dictender_type_type_type_type_type_type_type_type_type_type_type_type_type_type_type_type_type.\n",
      "                                          (*)$112080802111234567890808080211.html\n",
      "\n",
      "(*) ERROR REPORT REPORTINGLYLYSTEMSTEMSTEMOOLOOLOOLOOLOOLOOLINGINGING\n",
      "Layer 6: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 x x x x x x x............................................................................................\n",
      "Layer 7: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4.5%\n",
      "\n",
      "Advertisements<|endoftext|>Description Description Description Description Description Description Description Description Description\n",
      "Trivia Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit ]\n",
      "Trivia Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit ]\n",
      "Trivia Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit ]\n",
      "Trivia Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit Edit ]\n",
      "References Edit\n",
      "Layer 8: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "\n",
      "Layer 9: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "\n",
      "Layer 10: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 5 \n",
      "4 + 5 = 9 \n",
      "5 + 5 = 9 \n",
      "6 + 5 = 9 \n",
      "7 + 5 = 9 \n",
      "8 + 5 = 9 \n",
      "9 + 5 = 9 \n",
      "10 + 5 = 9 \n",
      "11 + 5 = 9 \n",
      "12 + 5 = 9 \n",
      "13 + 5 = 9 \n",
      "14 + 5 = 9 \n",
      "15 + 5 = 9 \n",
      "16 + 5 = 9 \n",
      "17 + 5 = 9 \n",
      "Layer 11: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 5 \n",
      "6 + 6 = 10 \n",
      "7 + 7 = 11 \n",
      "8 + 8 = 12 \n",
      "9 + 9 = 13 \n",
      "10 + 10 = 14 \n",
      "11 + 11 = 15 \n",
      "12 + 12 = 16 \n",
      "13 + 13 = 17 \n",
      "14 + 14 = 18 \n",
      "15 + 15 = 19 \n",
      "16 + 16 = 20 \n",
      "17 + 17 = 21 \n",
      "18 + 18 = 22 \n",
      "19 + 19 = 23 \n",
      "Layer 12: <|endoftext|>1 + 3 = 4 \n",
      "4 + 5 = 9\n",
      "2 + 3 = 5 \n",
      "6 + 4 = 10\n",
      "3 + 3 = 6 \n",
      "7 + 4 = 11\n",
      "8 + 4 = 12\n",
      "9 + 4 = 13\n",
      "10 + 4 = 14\n",
      "11 + 4 = 15\n",
      "12 + 4 = 16\n",
      "13 + 4 = 17\n",
      "14 + 4 = 18\n",
      "15 + 4 = 19\n",
      "16 + 4 = 20\n",
      "17 + 4 = 21\n",
      "18 + 4 = 22\n",
      "19 + 4 = 23\n",
      "20 + 4 = 24\n",
      "\n",
      "Layer 0: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \" corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid corrid\n",
      "Layer 1: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"nonozzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzlezzle\n",
      "Layer 2: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"true True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True\n",
      "Layer 3: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"true True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True\n",
      "Layer 4: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"true True True True......... ] ]\n",
      "\n",
      "(*) Updated update update notification notification notification notification notification notification notification notification notification notification.\n",
      "\n",
      "If you're not really bothered bother bother bothersomenessyieldings of the same thing happened hereticsticsticstics...............................................\n",
      "Layer 5: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"]\"], respectively.\n",
      "                                                          (*)$112080802111234567890808080211.html\n",
      "\n",
      "(*) Addeditionally supported support support for the same exact same thing happened to the same amount amount amount amount. Howevertonsteryteryteryteryteryteryteryteryteryteryteryteryteryteryteryteryteryteryterytery.completionist_classifications (...)................\n",
      "Layer 6: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"]\"], }elsewhereforeforeforementioned:\n",
      "                                          (*)$ $ $...............................................................................\n",
      "Layer 7: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \" etceterranormalities) ;;;;;;;;;;;;;;;*/[?]]\n",
      "                -|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|\n",
      "Layer 8: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"web browsers etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc., etc.,\n",
      "Layer 9: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"android]}, {\"name\": \"Alanjamin, Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr., Jr.,\n",
      "Layer 10: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"git\"]}, {\"name\": \"Alan\", \"age\": 27, \"skills\": [\"Microsoft Office\", \"git\"]}, {\"name\": \"Alan\", \"age\": 27, \"skills\": [\"Microsoft Office\", \"git\"]}, {\"name\": \"Alan\", \"age\": 27, \"skills\": [\"Microsoft Office\", \"git\"]}, {\"name\": \"Alan\", \"age\": 27, \"skills\": [\"Microsoft Office\", \"git\"]}, {\"name\": \"Alan\n",
      "Layer 11: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"python\"]}, {\"name\": \"Alan\", \"age\": 27, \"skills\": [\"Microsoft Office\", \"python\"]}, {\"name\": \"Alan\", \"age\": 26, \"skills\": [\"Microsoft Office\", \"python\"]}, {\"name\": \"Alan\", \"age\": 25, \"skills\": [\"Microsoft Office\", \"python\"]}, {\"name\": \"Alan\", \"age\": 24, \"skills\": [\"Microsoft Office\", \"python\"]}, {\"name\": \"Alan\n",
      "Layer 12: <|endoftext|>[{\"name\": \"James\", \"age\": 34, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 28, \"skills\": [\"MS Office\", \"python\"]}, {\"name\": \"Alan\", \"age\": 27, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 26, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 25, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\": 24, \"skills\": [\"Python\", \"git\"]}, {\"name\": \"Alan\", \"age\":\n",
      "Layer 0: <|endoftext|>Obama was elected in the year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year year\n",
      "Layer 1: <|endoftext|>Obama was elected in the year ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago ago\n",
      "Layer 2: <|endoftext|>Obama was elected in the yearlonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglong Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long Long\n",
      "Layer 3: <|endoftext|>Obama was elected in the yearlong ago ago ago when the same thing happened happening happening rightwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardwardward\n",
      "Layer 4: <|endoftext|>Obama was elected in the yearlong process process processionalized the same exact exact same exact same exact result.\n",
      "\n",
      "Theresa Theresa Theresa's own private sector sector sector sector sector sector sector sectorwidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewidewide\n",
      "Layer 5: <|endoftext|>Obama was elected in the yearlong celebration celebrating the same exact same thing happened happening around the same day when they're supposed to be able accessiblyibly disabled disabled disabled disabled disabled disabled disabled disabled.\n",
      "Howeverler's latest roundtrip tripship Yamato Takeru Takeru Takeru Takeru's own personalised version version version version version of the same thing happened happening apart apart apart. Itselfortiumortiumortiumortiumortiumortiumortium.\n",
      "       Another major difference difference between the same thing happening happening happening at least partially overlapping between the same amount amount amount\n",
      "Layer 6: <|endoftext|>Obama was elected in the yearlong campaign campaign campaign manager Mike Flynn's own personalised version of the same thing happenings happenings in the same vein vein. Buttonsholeholeholeholeholeholefuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckinstrumentation.\n",
      "                                        ••½½½½½½½½½½½½½½½½½½½½½½½½½½½½½½½½\n",
      "Layer 7: <|endoftext|>Obama was elected in the yearlong campaign campaign against the same kind of thing happening elsewhere elseworldly, albeit perhaps not necessarily necessarily deterministic, but nevertheless nonetheless nonetheless nonetheless nonetheless let us hope someday someday someday someday…\n",
      "            ••★️️‍♪️‍♪️‍♪️‍♪️‍♪️‍♪️‍♪️‍♪️‍♪️‍♪️‍♪️\n",
      "Layer 8: <|endoftext|>Obama was elected in the yearlong process of reformulation of the nation's economy, including the creation of new jobs jobs jobs jobs jobs jobs jobs jobs....\"\n",
      "\n",
      "Theresa Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel Merkel\n",
      "Layer 9: <|endoftext|>Obama was elected in the yearlong campaign campaign campaign against Hillary Clinton Hillary Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton Rodham Clinton\n",
      "Layer 10: <|endoftext|>Obama was elected in the year 2000, but he still had plenty of time to prepare for his presidency. During his tenure, he oversaw the creation of America's largest military force ever assembled, including military units stationed abroad overseas. During his tenure, he oversaw the creation of America's largest military force ever assembled, including military units stationed abroad overseas. During his tenure, he oversaw the creation of America's largest military force ever assembled, including military units stationed abroad overseas. During his tenure, he oversaw the creation of America's largest military\n",
      "Layer 11: <|endoftext|>Obama was elected in the year 2000, but he was still a candidate for president after his predecessor Barack Obama became president. Obama was elected in the year 2000, but he was still a candidate for president after his predecessor Barack Obama became president. Photo: Getty Images\n",
      "\n",
      "window._taboola = window._taboola || []; _taboola.push({flush: true});\n",
      "\n",
      "President Barack Obama greets supporters after his inauguration ceremony at the White House in Washington, DC, January 21, 2009. President Barack Obama greets supporters after his inauguration ceremony\n",
      "Layer 12: <|endoftext|>Obama was elected in the year 2000, and he was elected in 2008. He was elected in 2012, and he was elected in 2014. He was elected in 2016, and he was elected in 2017. He was elected in 2018, and he was elected in 2019. He was elected in 2020, and he was elected in 2021. He was elected in 2022, and he was elected in 2023. He was elected in 2024, and he was elected in 2025. He was elected in 2026, and he was\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "reference_text = \"The distance between the Colosseum and the Eiffel is approximately\"\n",
    "texts = [\n",
    "    \"The distance between Rome and Paris is approximately\",\n",
    "    \"1 + 3 = 4 \\n4 + 5 = 9\\n2 + 3 =\",\n",
    "    json.dumps([{'name': 'James', 'age': 34, 'skills': ['Python', 'git']}, {'name': 'Alan', 'age': 28, 'skills': ['MS Office', '<cut>']}]).split('<cut>')[0],\n",
    "    \"Obama was elected in the year\",\n",
    "]\n",
    "for prompt in texts:\n",
    "    for i in range(0, 13):\n",
    "        keep_layer_ids =  list(range(i))\n",
    "        permuted_model = permuted(demo_gpt2, keep_layer_ids)\n",
    "        text, _ = complete(permuted_model, prompt)\n",
    "        print(f\"Layer {i}: {text}\")\n",
    "        store({\n",
    "            'model': 'gpt-2-small',\n",
    "            'prompt': prompt,\n",
    "            'completion': text,\n",
    "            'ablation': {\n",
    "                'layers': keep_layer_ids\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prompt in texts:\n",
    "    for i in range(1, 13):\n",
    "        keep_layer_ids =  list(range(0, i))\n",
    "        permuted_model = permuted(demo_gpt2, keep_layer_ids)\n",
    "        text, _ = complete(permuted_model, prompt)\n",
    "        print(f\"Layer {i}: {text}\")\n",
    "        store({\n",
    "            'model': 'gpt-2-small',\n",
    "            'prompt': prompt,\n",
    "            'completion': text,\n",
    "            'ablation': {\n",
    "                'layers': keep_layer_ids\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at logit changes\n",
    "We now want to generate objects like this one:\n",
    "```\n",
    "{\n",
    "    'model': 'gpt-2-small',\n",
    "    'prompt': prompt,\n",
    "    'token': pos_id\n",
    "    'logit_diffs': [\n",
    "        {' hello': -10},\n",
    "        ...\n",
    "    ]\n",
    "    'ablation': ablation\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "reference_text = \"The distance between the Colosseum and the Eiffel is approximately\"\n",
    "texts = [\n",
    "    \"The distance between Rome and Paris is approximately\",\n",
    "    \"1 + 3 = 4 \\n4 + 5 = 9\\n2 + 3 =\",\n",
    "    json.dumps([{'name': 'James', 'age': 34, 'skills': ['Python', 'git']}, {'name': 'Alan', 'age': 28, 'skills': ['MS Office', '<cut>']}]).split('<cut>')[0],\n",
    "    \"Obama was elected in the year\",\n",
    "]\n",
    "for prompt in texts:\n",
    "    for i in range(0, 13):\n",
    "        keep_layer_ids =  list(range(i))\n",
    "        permuted_model = permuted(demo_gpt2, keep_layer_ids)\n",
    "        text, _ = complete(permuted_model, prompt)\n",
    "        print(f\"Layer {i}: {text}\")\n",
    "        store({\n",
    "            'model': 'gpt-2-small',\n",
    "            'prompt': prompt,\n",
    "            'completion': text,\n",
    "            'ablation': {\n",
    "                'layers': keep_layer_ids\n",
    "            }\n",
    "        })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
